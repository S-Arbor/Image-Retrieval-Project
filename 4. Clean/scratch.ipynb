{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sift Evaluator\n",
    "\n",
    "The objectives of this notebook are to:\n",
    "\n",
    "- Define functions that query the data based on different parameters (distance metric, transformations?)\n",
    "- Define functions to evaluate the truth of each returned query parameter\n",
    "- Define functions to calculate mAP and precision@k for the above output\n",
    "- Create a pipeline for evaluating the effects of different parameter set ups / transformations on mAP and p@k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "# Evaluation Functions\n",
    "____\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "import sklearn.metrics.pairwise\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import PIL\n",
    "import time\n",
    "import glob\n",
    "import copy\n",
    "import my_eval\n",
    "import sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded swin\n",
      "Loaded vgg\n",
      "Loaded resnet\n",
      "Loaded names\n",
      "Loaded vit\n",
      "Loaded names\n",
      "Loaded sift-10k\n",
      "Loaded sift-1k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.4381919 , -1.1369115 , -0.49100572, ..., -0.27456677,\n",
       "         0.38102797, -0.30554023],\n",
       "       [-0.19804995,  0.02098738,  0.52111053, ...,  0.44540596,\n",
       "         0.8620084 ,  0.18907186],\n",
       "       [ 1.0216093 , -0.06300209, -0.06569103, ...,  0.02202551,\n",
       "        -0.32440802,  0.3858102 ],\n",
       "       ...,\n",
       "       [ 0.74518114, -0.9655011 , -0.55623275, ..., -0.39560622,\n",
       "         0.3983633 , -0.4672271 ],\n",
       "       [ 0.4493655 , -0.97439206, -0.61376625, ..., -0.19914342,\n",
       "         0.27447924, -0.3482531 ],\n",
       "       [ 0.04259995,  0.09633142,  0.65417933, ...,  0.5438953 ,\n",
       "         0.53027916,  0.03832415]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "NOTEBOOK_DIR = \"/home/sean/Code/Pawsey/4. Clean\"\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "for data_subset in [\"oldenburger\", \"sutton\"]:\n",
    "    subdir = \"./data/\" + data_subset\n",
    "    data[data_subset] = {}\n",
    "\n",
    "    for descriptor in os.listdir(subdir):\n",
    "\n",
    "        if descriptor == \"names\":\n",
    "            data[data_subset][descriptor] = {\"ox\" : {}, \"par\" : {}}\n",
    "            for fname in os.listdir(subdir + \"/\" + descriptor):\n",
    "                split_name = fname[:-4].split(\"-\")\n",
    "                dataset = split_name[0]\n",
    "                if fname.endswith(\"y-names.npy\"):\n",
    "                    data[data_subset][descriptor][dataset][\"y\"] = np.load(\"./data/{}/{}/{}\".format(data_subset, descriptor, fname))\n",
    "                else:\n",
    "                    difficulty = split_name[2]\n",
    "                    data[data_subset][descriptor][dataset][difficulty] = np.load(\"./data/{}/{}/{}\".format(data_subset, descriptor, fname))\n",
    "\n",
    "        else:\n",
    "            data[data_subset][descriptor] = {\"ox\" : {\"E\" : {}, \"M\" : {}, \"H\" :{}},\n",
    "                                \"par\" : {\"E\" : {}, \"M\" : {}, \"H\" :{}}}\n",
    "            for fname in os.listdir(subdir + \"/\" + descriptor):\n",
    "                split_name = fname[:-4].split(\"-\")\n",
    "                if len(split_name) == 3:\n",
    "                    pass\n",
    "                else:\n",
    "                    (_, xy, dataset, difficulty) = split_name\n",
    "                    data[data_subset][descriptor][dataset][difficulty][xy] = np.load(\"./data/{}/{}/{}\".format(data_subset, descriptor, fname))\n",
    "        \n",
    "        print(\"Loaded \" + descriptor)\n",
    "\n",
    "data[\"oldenburger\"][\"swin\"][\"ox\"][\"E\"][\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_query(query, query_target, metric_function = sklearn.metrics.pairwise.euclidean_distances):\n",
    "    \"\"\"Return the indexes of the query_target images, arranged in ascending euclidean distance as compared to the query image\"\"\"\n",
    "    \n",
    "    query = query.reshape((1, -1))\n",
    "    D = metric_function(query_target, query).squeeze()\n",
    "    index = np.argsort(D)\n",
    "\n",
    "    return(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to carry out basic and expanded queries\n",
    "\n",
    "import sklearn.metrics.pairwise\n",
    "import numpy as np\n",
    "import diffusion\n",
    "\n",
    "def return_ranks(method, queries, gallery, **kwargs):\n",
    "\n",
    "    if method == \"basic\":\n",
    "        ranks = np.array([basic_query(query, gallery, **kwargs) for query in queries])\n",
    "        return(ranks)\n",
    "    elif method == \"diffusion\":\n",
    "        ranks = diffusion.diffusion_ranks(queries, gallery, **kwargs)\n",
    "        return(ranks)\n",
    "    elif method == \"expanded query\":\n",
    "        ranks = np.array([qe_query(query, gallery, **kwargs) for query in queries])\n",
    "        return(ranks)\n",
    "    \n",
    "\n",
    "def basic_query(query, query_target, metric_function = sklearn.metrics.pairwise.euclidean_distances):\n",
    "    \"\"\"Return the indexes of the query_target images, arranged in ascending euclidean distance as compared to the query image\"\"\"\n",
    "    \n",
    "    query = query.reshape((1, -1))\n",
    "    D = metric_function(query_target, query).squeeze()\n",
    "    index = np.argsort(D)\n",
    "\n",
    "    return(index)\n",
    "\n",
    "def qe_query(query, query_target, metric_function=sklearn.metrics.pairwise.euclidean_distances, type=\"qe baseline\", n=5, alpha=1):\n",
    "    \"\"\"Run a query with query expansion, supported methods:\n",
    "       - \"qe baseline\" : described in Total Recall (2007), new result is based on alpha proportion of requerying (e.g. alpha = 1,\n",
    "                         then results after the top 5 will be completely determined by the top five\"\"\"\n",
    "    \n",
    "    original_results = basic_query(query, query_target, metric_function)\n",
    "\n",
    "    if type == \"qe baseline\":\n",
    "        # find top n results, combine top n into a new query, append results of new query to top n\n",
    "        top_n_results = original_results[:n]\n",
    "        second_query = np.average(query_target[top_n_results], axis=0)\n",
    "        \n",
    "        if alpha != 1:\n",
    "            combined_queries = np.vstack([query, second_query])\n",
    "            second_query = np.average([query, second_query], axis = 0, weights = [1-alpha, alpha])\n",
    "            \n",
    "        new_results = basic_query(second_query, query_target, metric_function)\n",
    "        pruned_new_results = new_results[np.logical_not(np.isin(new_results, top_n_results))]\n",
    "        results = np.concatenate([top_n_results, pruned_new_results])\n",
    "\n",
    "        return(results)\n",
    "\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [1, 1],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0,0],[1,1],[2,2],[3,3]])\n",
    "a[[2,1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = data[\"oldenburger\"][\"swin\"][\"ox\"][\"E\"][\"y\"]\n",
    "t = data[\"oldenburger\"][\"swin\"][\"ox\"][\"E\"][\"x\"]\n",
    "q_n = data[\"oldenburger\"][\"names\"][\"ox\"][\"y\"]\n",
    "t_n = data[\"oldenburger\"][\"names\"][\"ox\"][\"E\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = return_ranks(\"expanded query\", q, t, alpha = 0)\n",
    "len(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8838282489082855,\n",
       " {1: 0.8857142857142857, 5: 0.7371428571428572, 10: 0.6728571428571429})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_eval.evaluate(ranks, q_n, t_n)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
