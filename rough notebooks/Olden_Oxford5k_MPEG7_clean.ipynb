{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford5k + MPEG7 Image Retrieval:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean version of all functions used to compute the metrics/Image retrieval of either MPEG7 or Oxford5k dataset\n",
    "\n",
    "At the bottom of the page is the functions to run them, and instructions on inputted variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Oxford Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(images_path, gt_path):\n",
    "    test_images_path = []\n",
    "    test_names = []\n",
    "    test_gray_images = []\n",
    "    test_colour_images = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(gt_path)):\n",
    "        if filename.endswith(\"query.txt\"):\n",
    "            \n",
    "            # Saving filename\n",
    "            tmp = filename.split(\".\")[0].split(\"_\")\n",
    "            if len(tmp) == 4:\n",
    "                name = tmp[0]+\"_\"+tmp[1]\n",
    "            elif len(tmp) == 3:\n",
    "                name = tmp[0]\n",
    "            test_names.append(name)\n",
    "\n",
    "            # Reading the image number to be saved\n",
    "            with open(os.path.join(gt_path, filename), \"r\") as f:\n",
    "                line = f.readline()\n",
    "                test_images_path.append(line.split(\" \")[0])\n",
    "    \n",
    "    for path in test_images_path:\n",
    "        image = cv2.imread(os.path.join(images_path, path[5:]) + \".jpg\")\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        test_gray_images.append(gray_image)\n",
    "        test_colour_images.append(image)\n",
    "    \n",
    "    print(\"Loaded in {} Images!\".format(len(test_gray_images)))\n",
    "    \n",
    "    return test_gray_images, test_colour_images, test_names, test_images_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Oxford Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314357</td>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.288328</td>\n",
       "      <td>0.203231</td>\n",
       "      <td>0.247281</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.269306</td>\n",
       "      <td>0.321365</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.422480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323421</td>\n",
       "      <td>0.171378</td>\n",
       "      <td>0.285630</td>\n",
       "      <td>0.188076</td>\n",
       "      <td>0.267174</td>\n",
       "      <td>0.565107</td>\n",
       "      <td>0.249596</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.323421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382649</td>\n",
       "      <td>0.202579</td>\n",
       "      <td>0.280109</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.217585</td>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.335131</td>\n",
       "      <td>0.290113</td>\n",
       "      <td>0.380148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298072</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.276083</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.305401</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.309066</td>\n",
       "      <td>0.285856</td>\n",
       "      <td>0.273640</td>\n",
       "      <td>0.316396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.148814</td>\n",
       "      <td>0.304391</td>\n",
       "      <td>0.257042</td>\n",
       "      <td>0.228632</td>\n",
       "      <td>0.274629</td>\n",
       "      <td>0.247572</td>\n",
       "      <td>0.403149</td>\n",
       "      <td>0.347683</td>\n",
       "      <td>0.482968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.251836</td>\n",
       "      <td>0.334334</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.258349</td>\n",
       "      <td>0.492817</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.329992</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.360386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.237406</td>\n",
       "      <td>0.221256</td>\n",
       "      <td>0.224486</td>\n",
       "      <td>0.179266</td>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.197031</td>\n",
       "      <td>0.332153</td>\n",
       "      <td>0.299315</td>\n",
       "      <td>0.654617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.352977</td>\n",
       "      <td>0.186982</td>\n",
       "      <td>0.301461</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.233728</td>\n",
       "      <td>0.417848</td>\n",
       "      <td>0.262348</td>\n",
       "      <td>0.374919</td>\n",
       "      <td>0.237544</td>\n",
       "      <td>0.427388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.222150</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.283858</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>0.235520</td>\n",
       "      <td>0.376421</td>\n",
       "      <td>0.280773</td>\n",
       "      <td>0.266374</td>\n",
       "      <td>0.401104</td>\n",
       "      <td>0.404190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.412206</td>\n",
       "      <td>0.120135</td>\n",
       "      <td>0.177447</td>\n",
       "      <td>0.445821</td>\n",
       "      <td>0.197286</td>\n",
       "      <td>0.162568</td>\n",
       "      <td>0.269477</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.449128</td>\n",
       "      <td>0.269477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.314357  0.166189  0.288328  0.203231  0.247281  0.408464  0.269306   \n",
       "1    0.323421  0.171378  0.285630  0.188076  0.267174  0.565107  0.249596   \n",
       "2    0.382649  0.202579  0.280109  0.296366  0.217585  0.437671  0.257600   \n",
       "3    0.298072  0.195457  0.276083  0.195457  0.305401  0.559495  0.309066   \n",
       "4    0.336860  0.148814  0.304391  0.257042  0.228632  0.274629  0.247572   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "562  0.321308  0.251836  0.334334  0.238810  0.258349  0.492817  0.240981   \n",
       "563  0.312773  0.237406  0.221256  0.224486  0.179266  0.216949  0.197031   \n",
       "564  0.352977  0.186982  0.301461  0.268072  0.233728  0.417848  0.262348   \n",
       "565  0.222150  0.391848  0.283858  0.212894  0.235520  0.376421  0.280773   \n",
       "566  0.412206  0.120135  0.177447  0.445821  0.197286  0.162568  0.269477   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.321365  0.408464  0.422480  \n",
       "1    0.313753  0.304965  0.323421  \n",
       "2    0.335131  0.290113  0.380148  \n",
       "3    0.285856  0.273640  0.316396  \n",
       "4    0.403149  0.347683  0.482968  \n",
       "..        ...       ...       ...  \n",
       "562  0.329992  0.240981  0.360386  \n",
       "563  0.332153  0.299315  0.654617  \n",
       "564  0.374919  0.237544  0.427388  \n",
       "565  0.266374  0.401104  0.404190  \n",
       "566  0.416063  0.449128  0.269477  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"/home/sean/Code/Pawsey/oxford_data/\"\n",
    "\n",
    "def load_data(name):\n",
    "    \"\"\"Returns a dictionary of attributes and 1 of features for train or test data\"\"\"\n",
    "\n",
    "    attributes = {}\n",
    "    \n",
    "    for img_att in [\"names\", \"pixels\", \"images\"]:\n",
    "        attributes[img_att] = np.load(BASE_DIR + name + \"_\" + img_att + \".npy\", allow_pickle=True)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    os.chdir(BASE_DIR + \"NPY files for BoVW/\")\n",
    "    for bovw_size in os.listdir():\n",
    "        features[bovw_size] = pandas.DataFrame(np.load(bovw_size + \"/BoW_\" + name.capitalize() + \".npy\"))\n",
    "    \n",
    "    return(attributes, features)\n",
    "\n",
    "(test_attributes, test_features) = load_data(\"test\")\n",
    "(train_attributes, train_features) = load_data(\"train\")\n",
    "train_features[\"bovw files for 10 Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 55 Test images | 567 Train images\n",
      "\n",
      "Loaded in 55 Test names | 567 Train names\n",
      "\n",
      "Loaded in 55 Test pixels | 567 Train pixels\n",
      "\n",
      "Loaded in 55 Test 10-dim SIFT features | 567 Train 10-dim SIFT features\n",
      "Loaded in 55 Test 100-dim SIFT features | 567 Train 100-dim SIFT features\n",
      "Loaded in 55 Test 1000-dim SIFT features | 567 Train 1000-dim SIFT features\n",
      "Loaded in 55 Test 10000-dim SIFT features | 567 Train 10000-dim SIFT features\n",
      "Loaded in 55 Test 20000-dim SIFT features | 567 Train 20000-dim SIFT features\n",
      "Loaded in 55 Test 50000-dim SIFT features | 567 Train 50000-dim SIFT features\n",
      "Loaded in 55 Test 100000-dim SIFT features | 567 Train 100000-dim SIFT features\n",
      "\n",
      "Loading Complete!\n",
      "\n",
      "File names: test_images, train_images, test_names, train_names, test_pixels, train_pixels, SIFT_features\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# setting path name (make sure this notebook and the oxford_data folder are in the same directory/folder)\n",
    "os.chdir(\"/home/sean/Code/Pawsey/\")\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"oxford_data\")\n",
    "\n",
    "# Loading in Images:\n",
    "test_images = np.load(os.path.join(path, \"test_images.npy\"), allow_pickle=True)\n",
    "train_images = np.load(os.path.join(path, \"train_images.npy\"), allow_pickle=True)\n",
    "print(\"Loaded in {} Test images | {} Train images\\n\".format(len(test_images), len(train_images)))\n",
    "\n",
    "# Loading in Names:\n",
    "test_names = np.load(os.path.join(path, \"test_names.npy\"), allow_pickle=True)\n",
    "train_names= np.load(os.path.join(path, \"train_names.npy\"), allow_pickle=True)\n",
    "print(\"Loaded in {} Test names | {} Train names\\n\".format(len(test_names), len(train_names)))\n",
    "\n",
    "# Loading in Pixel features:pixels\n",
    "test_pixels = np.load(os.path.join(path, \"test_pixels.npy\"), allow_pickle=True)\n",
    "train_pixels= np.load(os.path.join(path, \"train_pixels.npy\"), allow_pickle=True)\n",
    "print(\"Loaded in {} Test pixels | {} Train pixels\\n\".format(len(test_pixels), len(train_pixels)))\n",
    "\n",
    "# Loading in SIFT features:\n",
    "SIFT_features = [[],[],[],[],[],[],[]]\n",
    "new_path = os.path.join(path, \"NPY files for BoVW\")\n",
    "for idx, i in enumerate([10, 100, 1000, 10000, 20000, 50000, 100000]):\n",
    "    path = os.path.join(new_path, \"bovw files for {} Words\".format(i))\n",
    "    test = np.load(os.path.join(path, \"BoW_Test.npy\"), allow_pickle=True)\n",
    "    train = np.load(os.path.join(path, \"BoW_Train.npy\"), allow_pickle=True)\n",
    "    SIFT_features[idx].append(test)\n",
    "    SIFT_features[idx].append(train)\n",
    "    print(\"Loaded in {} Test {}-dim SIFT features | {} Train {}-dim SIFT features\".format(len(test_images), i, len(train_images), i))\n",
    "    \n",
    "print(\"\\nLoading Complete!\\n\")\n",
    "print(\"File names: test_images, train_images, test_names, train_names, test_pixels, train_pixels, SIFT_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07355445, 0.07490411, 0.06076237, ..., 0.10873266, 0.05436633,\n",
       "        0.08634653],\n",
       "       [0.02450643, 0.13725855, 0.07351928, ..., 0.04411157, 0.08087121,\n",
       "        0.07351928],\n",
       "       [0.0231921 , 0.12821013, 0.05963683, ..., 0.07288946, 0.0927684 ,\n",
       "        0.0695763 ],\n",
       "       ...,\n",
       "       [0.08292598, 0.07389165, 0.09121858, ..., 0.07463338, 0.10780378,\n",
       "        0.08292598],\n",
       "       [0.05177144, 0.07531628, 0.08135512, ..., 0.07026124, 0.02218776,\n",
       "        0.09244899],\n",
       "       [0.07477707, 0.05178143, 0.07178599, ..., 0.06281274, 0.08973248,\n",
       "        0.09272357]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIFT_features[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_retrieval_k(train_data, test_data, train_names, test_names, train_images_as_array, test_images_as_array, k=20, view_option=0, image_size=(32,32), border_size=20):\n",
    "    avg_precisions = []\n",
    "    avg_recalls = []\n",
    "    precisionsatk = []\n",
    "    count = 0\n",
    "    \n",
    "    for idx, query in enumerate(test_data):\n",
    "        \n",
    "        all_precisions = []\n",
    "        all_recalls = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "\n",
    "        # Finding the euclidean distance from the query image and sorting them into index\n",
    "        query = query.reshape((1, -1))\n",
    "        D = euclidean_distances(train_data, query).squeeze()\n",
    "        index = np.argsort(D)\n",
    "        \n",
    "        # Finding the index of the last correct image in the sorted index to iter to\n",
    "        last_correct_image_idx = 0\n",
    "        for i in range(len(index)):\n",
    "            if train_names[index[i]] == test_names[idx]:\n",
    "                last_correct_image_idx = i\n",
    "        \n",
    "        # make sure we iter to k (for precision@k) if all correct images are found before k\n",
    "        if k > last_correct_image_idx:\n",
    "            last_correct_image_idx = k+1\n",
    "        \n",
    "        # Itering through all images untill we get to k or last correct image to compute AP\n",
    "        for kk in range(1, last_correct_image_idx+2):\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            \n",
    "            # Finding the correct amount of images in the training set\n",
    "            correct_count = 0\n",
    "            for ind in index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    correct_count += 1\n",
    "            sized_index = index[:kk]\n",
    "            \n",
    "            # Find TP FP FN\n",
    "            for ind in sized_index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            FN = correct_count - TP\n",
    "            \n",
    "            # If we want to view the images then we run this code, else its a waste of computational time\n",
    "            if view_option == 1:\n",
    "                # Creating image of k images (including query image at start)\n",
    "                tmp = [query.reshape(image_size)]\n",
    "                for ind in sized_index[:k]:\n",
    "                    tmp.append(train_data[ind].reshape(image_size))\n",
    "                output = np.array(tmp)*255\n",
    "                output = output.transpose(1, 0, 2)\n",
    "                output = output.reshape((image_size[0], -1))\n",
    "                im_query = Image.fromarray(output)\n",
    "            \n",
    "            # If the last k image is a correct image we add precision to the list\n",
    "            if train_names[sized_index[-1]] == test_names[idx]:\n",
    "                try:\n",
    "                    precisions.append(TP/(TP+FP))\n",
    "                except ZeroDivisionError:\n",
    "                    precisions.append(0)\n",
    "                try:\n",
    "                    recalls.append(TP/(TP+FN))\n",
    "                except ZeroDivisionError:\n",
    "                    recalls.append(0)\n",
    "\n",
    "            # Adding all precisions and recalls to a seperate list\n",
    "            try:\n",
    "                all_precisions.append(TP/(TP+FP))\n",
    "            except ZeroDivisionError:\n",
    "                all_precisions.append(0)\n",
    "            try:\n",
    "                all_recalls.append(TP/(TP+FN))\n",
    "            except ZeroDivisionError:\n",
    "                all_recalls.append(ZeroDivisionError)\n",
    "     \n",
    "        # Solving AP, AR and precision@k\n",
    "        avg_precisions.append(np.average(precisions))\n",
    "        avg_recalls.append(np.average(all_recalls))\n",
    "        precisionsatk.append(all_precisions[k-1])\n",
    "        \n",
    "        # Set a viewing option, if 1 we print out the following:\n",
    "        if view_option == 1:\n",
    "            display(im_query) \n",
    "            print(\"Label: {}\".format(test_names[idx]))\n",
    "            print(\"Average Precision for query {}: \".format(idx), avg_precisions[-1])\n",
    "            print(\"Precision@k for query {}: \".format(idx), precisionsatk[-1])\n",
    "            print(\"\\n\")\n",
    "        elif view_option == 0:\n",
    "            count += 1 \n",
    "            print(\"Percentage Complete: {}\".format(round((count/len(test_data))*100),2), end=\"\\r\")\n",
    "        elif view_option == 2:\n",
    "            # Allowing a view_option 2 -> for viewing top k images from non_pixel value inputs\n",
    "            # creating an array of the top k similar images\n",
    "            top_k_images = [test_images_as_array[idx]]\n",
    "            for i in range(0,k):\n",
    "                top_k_images.append(train_images_as_array[index[i]])\n",
    "\n",
    "            fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "            for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "                # convert image to RGB and add border:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # resize image if border size greater than 10:\n",
    "                if border_size >= 10:\n",
    "                    image = cv2.resize(image, (250, 400), interpolation=cv2.INTER_CUBIC)\n",
    "                if i == 0:\n",
    "                    query_name = test_names[idx]\n",
    "                    title = \"Query: {}\".format(query_name)\n",
    "                    color = (0, 255, 0)\n",
    "                    image = border(image, color, border_size)\n",
    "                else:\n",
    "                    title = train_names[sized_index[i-1]]\n",
    "                    if train_names[sized_index[i-1]] == query_name:\n",
    "                        color = (0, 255, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                    else:\n",
    "                        color = (255, 0, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                # display all set options\n",
    "                ax.imshow(image, cmap=\"gray\")\n",
    "                ax.set_title(title)\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "            print(\"Label: {}\".format(test_names[idx]))\n",
    "            print(\"Average Precision for query {}: \".format(idx), avg_precisions[-1])\n",
    "            print(\"Precision@k for query {}: \".format(idx), precisionsatk[-1])\n",
    "            print(\"\\n\")\n",
    "        elif view_option == 3:\n",
    "            top_k_images = [test_images_as_array[idx]]\n",
    "            for i in range(0,k):\n",
    "                top_k_images.append(train_images_as_array[index[i]])\n",
    "\n",
    "            fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "            for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "                # convert image to RGB and add border:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # resize image if border size greater than 10:\n",
    "                if border_size >= 10:\n",
    "                    image = cv2.resize(image, (250, 400), interpolation=cv2.INTER_CUBIC)\n",
    "                if i == 0:\n",
    "                    query_name = test_names[idx]\n",
    "                    title = \"Query: {}\".format(query_name)\n",
    "                else:\n",
    "                    title = train_names[sized_index[i-1]]\n",
    "                    if train_names[sized_index[i-1]] == query_name:\n",
    "                        color = (0, 255, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                    else:\n",
    "                        color = (255, 0, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                # display all set options\n",
    "                ax.imshow(image, cmap=\"gray\")\n",
    "                ax.set_title(title)\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "    return avg_precisions, avg_recalls, precisionsatk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_csv(_precisionsatk, _AP, _k, _dataset_name):\n",
    "    data = {'Precision@k': _precisionsatk, 'Average Precision': _AP}\n",
    "    df = pandas.DataFrame(data=data)\n",
    "    pandas.set_option(\"display.max_rows\", 500, \"display.max_columns\", 4)\n",
    "    df.to_csv('{}-metrics_k={}.csv'.format(_dataset_name, _k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford 5k dataset func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oxford5k_Image_Retrieval(images_path, gt_path, pixelorsift=\"sift\", savedata=0, n_clusters=100, k=10, view_option=2):\n",
    "    if pixelorsift == \"pixel\":\n",
    "        # Load in data\n",
    "        print(\"Loading Images...\")\n",
    "        test_gray_images, test_colour_images, test_names, test_imgs_path = load_test_data(images_path, gt_path)\n",
    "        train_gray_images, train_colour_images, train_names = load_train_data(images_path, gt_path, test_imgs_path)\n",
    "        \n",
    "        # Compute pixel values\n",
    "        print(\"\\nComputing Pixel Values...\")\n",
    "        test_pixels, train_pixels = find_pixel_values(test_gray_images, train_gray_images)\n",
    "        \n",
    "        # Compute metrics\n",
    "        print(\"\\nComputing Metics...\")\n",
    "        AP, AR, precisionsatk = image_retrieval_k(train_pixels, test_pixels, train_names, test_names, train_colour_images, test_colour_images, k, view_option, border_size=20)\n",
    "\n",
    "        # Display mAP\n",
    "        mAP = np.average(AP)\n",
    "        print(\"\\nmAP =\", mAP)\n",
    "        \n",
    "        # Save data\n",
    "        if savedata == 1:\n",
    "            save_data_to_csv(precisionsatk, AP, k, \"Oxford5k_pixelvalues\")\n",
    "            print(\"\\nData saved to csv\")\n",
    "        \n",
    "    elif pixelorsift == \"sift\":\n",
    "        # Load in data\n",
    "        print(\"Loading Images...\")\n",
    "        test_gray_images, test_colour_images, test_names, test_imgs_path = load_test_data(images_path, gt_path)\n",
    "        train_gray_images, train_colour_images, train_names = load_train_data(images_path, gt_path, test_imgs_path)\n",
    "        \n",
    "        # Copmuting bovw\n",
    "        print(\"\\nComputing test SIFT features...\")\n",
    "        test_kp, test_desc = SIFT(test_gray_images)\n",
    "        print(\"\\nComputing train SIFT features...\")\n",
    "        train_kp, train_desc = SIFT(train_gray_images)\n",
    "        stacked_train_desc = stack_descriptors(train_desc)\n",
    "        \n",
    "        print(\"\\nClustering Descriptors...\")\n",
    "        cluster_func = cluster(stacked_train_desc, n_clusters)\n",
    "        \n",
    "        print(\"\\nComputing test BoVW...\")\n",
    "        test_bovw  = solve_BoW(test_desc, cluster_func, n_clusters)\n",
    "        print(\"\\nComputing train BoVW...\")\n",
    "        train_bovw = solve_BoW(train_desc, cluster_func, n_clusters)\n",
    "        \n",
    "        # Compute metrics\n",
    "        print(\"\\nComputing Metrics...\")\n",
    "        AP, AR, precisionsatk = image_retrieval_k(train_bovw, test_bovw, train_names, test_names, train_colour_images, test_colour_images, k, view_option, border_size=20)\n",
    "        \n",
    "        # Display mAP\n",
    "        mAP = np.average(AP)\n",
    "        print(\"\\nmAP =\", mAP)\n",
    "        \n",
    "        # Save data\n",
    "        if savedata == 1:\n",
    "            save_data_to_csv(precisionsatk, AP, k, \"Oxford5k_BoVW_{}\".format(n_clusters))\n",
    "            print(\"\\nData saved to csv\")\n",
    "\n",
    "    else:\n",
    "        print(\"3rd input must be either: \\\"pixel\\\" or \\\"sift\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPEG7 dataset func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "AP, AR, precisionsatk = image_retrieval_k(SIFT_features[0][1], SIFT_features[0][0], train_names, test_names, train_images_as_array=False, test_images_as_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2846602906055916"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(AP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
