{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints_per_image = []\n",
    "    descriptor_per_image = []\n",
    "    \n",
    "    count = 0\n",
    "    for image in images:\n",
    "        keypoints, descriptor = sift.detectAndCompute(image, None)\n",
    "\n",
    "        keypoints_per_image.append(keypoints)\n",
    "        descriptor_per_image.append(descriptor)\n",
    "        \n",
    "        count += 1 \n",
    "        print(\"Percentage Completed: {}%\".format(round((count/len(images))*100), 2), end=\"\\r\")\n",
    "    \n",
    "    print(\"\")\n",
    "    return keypoints_per_image, descriptor_per_image\n",
    "\n",
    "def stack_descriptors(descriptors):\n",
    "    stack = []\n",
    "    \n",
    "    for desc in descriptors:\n",
    "        tmp = np.array(desc)\n",
    "        if tmp.shape:\n",
    "            stack.append(tmp)\n",
    "            \n",
    "    all_descriptors = np.vstack(i for i in stack)\n",
    "    \n",
    "    return all_descriptors\n",
    "\n",
    "def cluster(data, n_clusters=100, cluster_type=\"minibatch\"):\n",
    "    start = time.time()\n",
    "    \n",
    "    if cluster_type == \"minibatch\":\n",
    "        cluster = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "        y_cluster = cluster.fit(data)\n",
    "    elif cluster_type == \"kmeans\":\n",
    "        cluster = KMeans(n_clusters=n_clusters)\n",
    "        y_cluster = cluster.fit(data)\n",
    "    else:\n",
    "        print(\"Unknown cluster_type! Try: 'minibatch' or 'kmeans'\")\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Time Elapsed: {} min\".format(round((end - start)/60, 2)))\n",
    "    return y_cluster\n",
    "\n",
    "def solve_BoW(descriptors, y_cluster, n_clusters):\n",
    "    previous = 0\n",
    "    count = 0\n",
    "    image_words = []\n",
    "    for image_number in range(len(descriptors)):\n",
    "        if descriptors[image_number] is not None:\n",
    "            tmp = []\n",
    "            for kp in descriptors[image_number]:\n",
    "                cluster = y_cluster.predict(np.array([kp]))\n",
    "                tmp.append(cluster[0])\n",
    "            image_words.append(tmp)\n",
    "            \n",
    "            count += 1\n",
    "            print(\"(1/2) Percentage Completed: {}%\".format(round((count/len(descriptors))*100), 2), end=\"\\r\")\n",
    "        else:\n",
    "            # If image has no desciptors, append 0 words to it\n",
    "            image_words.append([0])\n",
    "    \n",
    "    print(\"\")\n",
    "    count = 0\n",
    "    image_histograms = []\n",
    "    for image in range(len(image_words)):\n",
    "        hist = np.zeros(n_clusters)\n",
    "        for words in image_words[image]:\n",
    "            hist[words-1] = hist[words-1]+1\n",
    "        image_histograms.append(hist)\n",
    "        \n",
    "        count += 1\n",
    "        print(\"(2/2) Percentage Completed: {}%\".format(round((count/len(image_words))*100), 2), end=\"\\r\")\n",
    "    \n",
    "    print(\"\")\n",
    "    # Transforming data using tf-idf:\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    weighted_image_histograms = transformer.fit_transform(image_histograms).toarray()\n",
    "    \n",
    "    return weighted_image_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_retrieval_k(train_data, test_data, train_names, test_names, train_images, test_images, k=10, view_option=0, border_size=3, print_opt=True):\n",
    "    avg_precisions = []\n",
    "    precisionsatk = []\n",
    "    count = 0\n",
    "    \n",
    "    for idx, query in enumerate(test_data):\n",
    "        all_precisions = []\n",
    "        precisions = []\n",
    "        \n",
    "        # Finding similarity order:\n",
    "        query = query.reshape((1, -1))\n",
    "        D = euclidean_distances(train_data, query).squeeze()\n",
    "        D = 1-D\n",
    "        index = np.argsort(D)\n",
    "        \n",
    "        # Finding the index of the last correct image in the sorted index to iter to\n",
    "        last_correct_image_idx = 0\n",
    "        for i in range(len(index)):\n",
    "            if train_names[index[i]] == test_names[idx]:\n",
    "                last_correct_image_idx = i\n",
    "        \n",
    "        # make sure we iter to k (for precision@k) if all correct images are found before k\n",
    "        if k > last_correct_image_idx:\n",
    "            last_correct_image_idx = k+1\n",
    "        \n",
    "        # Itering through all images untill we get to k or last correct image to compute AP\n",
    "        for kk in range(1, last_correct_image_idx+2):\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            \n",
    "            # Finding the correct amount of images in the training set\n",
    "            correct_count = 0\n",
    "            for ind in index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    correct_count += 1\n",
    "            sized_index = index[:kk]\n",
    "            \n",
    "            # Find TP FP FN\n",
    "            for ind in sized_index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            FN = correct_count - TP\n",
    "            \n",
    "            # If the last k image is a correct image we add precision to the list\n",
    "            if train_names[sized_index[-1]] == test_names[idx]:\n",
    "                precisions.append(TP/(TP+FP))\n",
    "                \n",
    "            # Adding all precisions and recalls to a seperate list\n",
    "            all_precisions.append(TP/(TP+FP))\n",
    "        \n",
    "        # Solving AP and precision@k\n",
    "        avg_precisions.append(np.average(precisions))\n",
    "        precisionsatk.append(all_precisions[k-1])\n",
    "        \n",
    "        # display retrieval:\n",
    "        if view_option == 0:\n",
    "            count += 1\n",
    "            if print_opt:\n",
    "                print(\"Percentage Complete: {}%\".format(round((count/len(test_data))*100),2), end=\"\\r\")\n",
    "        elif view_option == 1:\n",
    "            display_retrieval(test_data, test_images, idx, train_images, index, test_names, train_names, sized_index, avg_precisions[-1], precisionsatk[-1], border_size, k=k)\n",
    "            \n",
    "    return avg_precisions, precisionsatk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_retrieval(test_data, test_images, idx, train_images, index, test_names, train_names, sized_index, avg_precisions, precisionsatk, border_size, k):\n",
    "    top_k_images = [test_images[idx]]\n",
    "    for i in range(0,k):\n",
    "        top_k_images.append(train_images[index[i]])\n",
    "\n",
    "    fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "    for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "        if i == 0:\n",
    "            query_name = test_names[idx]\n",
    "            title = \"Query: {}\".format(query_name)\n",
    "        else:\n",
    "            title = train_names[sized_index[i-1]]\n",
    "            if train_names[sized_index[i-1]] == query_name:\n",
    "                color = (0, 255, 0)\n",
    "                image = border(image, color, border_size)\n",
    "            else:\n",
    "                color = (255, 0, 0)\n",
    "                image = border(image, color, border_size)\n",
    "        # display all set options\n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(\"Label: {}\".format(test_names[idx]))\n",
    "    print(\"Average Precision for query {}: \".format(idx), avg_precisions)\n",
    "    print(\"Precision@k for query {}: \".format(idx), precisionsatk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border(img, color, border_size):\n",
    "    # get dimensions\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # make a base slightly bigger than image\n",
    "    base_size= h+(border_size*2), w+(border_size*2), 3\n",
    "    base = np.zeros(base_size, dtype=np.uint8)\n",
    "\n",
    "    # make a boundary of chosen color\n",
    "    cv2.rectangle(base, (0,0), (w+20,h+20), color, 30)\n",
    "\n",
    "    # put original image into base\n",
    "    base[border_size:h+border_size, border_size:w+border_size] = img\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(trn_features, val_features, dim=256, print_opt=True):\n",
    "    # PCA Dimension reduction\n",
    "    pca = PCA(n_components=dim)\n",
    "    pca.fit(trn_features)\n",
    "\n",
    "    # Dimension reduction\n",
    "    trn_features = pca.transform(trn_features)\n",
    "    val_features = pca.transform(val_features)\n",
    "\n",
    "    if print_opt:\n",
    "        print(\"Train Features shape: {} | Valid Features shape: {}\".format(trn_features.shape, val_features.shape))\n",
    "    \n",
    "    return trn_features, val_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SIFT(test_gray_images, train_gray_images, n_clusters):\n",
    "    # Copmuting bovw\n",
    "    print(\"\\nComputing test SIFT features...\")\n",
    "    test_kp, test_desc = SIFT(test_gray_images)\n",
    "\n",
    "    print(\"\\nComputing train SIFT features...\")\n",
    "    train_kp, train_desc = SIFT(train_gray_images)\n",
    "    stacked_train_desc = stack_descriptors(train_desc)\n",
    "\n",
    "    print(\"\\nClustering Descriptors...\")\n",
    "    cluster_func = cluster(stacked_train_desc, n_clusters)\n",
    "\n",
    "    print(\"\\nComputing test BoVW...\")\n",
    "    test_bovw  = solve_BoW(test_desc, cluster_func, n_clusters)\n",
    "    print(\"\\nComputing train BoVW...\")\n",
    "    train_bovw = solve_BoW(train_desc, cluster_func, n_clusters)\n",
    "    \n",
    "    return test_bovw, train_bovw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in images & names here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: 516 | Query Images: 70\n"
     ]
    }
   ],
   "source": [
    "def load_data(train_path, query_path):\n",
    "\n",
    "    train_image_paths = []\n",
    "    train_images = []\n",
    "    train_names = []\n",
    "\n",
    "    # save path to image and save class names as numbers (train)\n",
    "    for data_path in glob.glob(train_path + '/*'):\n",
    "        name = data_path.split('/')[-1].split(\"-\")[0]\n",
    "        train_names.append(name) \n",
    "        train_image_paths.append(data_path)\n",
    "    \n",
    "    # open image from path and save to array\n",
    "    for img_path in train_image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        train_images.append(img)\n",
    "\n",
    "    # save path to image and save class names as numbers (query)\n",
    "    query_image_paths = []\n",
    "    query_names = []\n",
    "    query_images = []\n",
    "    \n",
    "    for data_path in glob.glob(query_path + '/*'):\n",
    "        name = data_path.split('/')[-1].split(\"-\")[0]\n",
    "        query_names.append(name) \n",
    "        query_image_paths.append(data_path)\n",
    "    \n",
    "    # open image from path and save to array\n",
    "    for img_path in query_image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        query_images.append(img)\n",
    "\n",
    "    print(\"Train Images: {} | Query Images: {}\".format(len(train_images), len(query_images)))\n",
    "    return train_images, train_names, query_images, query_names\n",
    "\n",
    "option = 'easy'\n",
    "train_path = \"/home/sean/Code/Pawsey/3. Data/Revised and Sorted/roxford5k/{}\".format(option)\n",
    "query_path = \"/home/sean/Code/Pawsey/3. Data/Revised and Sorted/roxford5k/query\"\n",
    "\n",
    "ox_easy_images, ox_easy_names, ox_query_images, ox_query_names = load_data(train_path, query_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For roxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to load in colour and gray images\n",
    "test_colour_images = ox_query_images\n",
    "train_colour_images = ox_easy_images\n",
    "\n",
    "test_gray_images = [cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in test_colour_images]\n",
    "train_gray_images = [cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in train_colour_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in names:\n",
    "test_names = ox_query_names\n",
    "train_names = ox_easy_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For oxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_colour_images = np.load(\"/home/sean/Code/Pawsey/1. Initial Analysis/oxford_data/test_images.npy\", allow_pickle=True)\n",
    "train_colour_images = np.load(\"/home/sean/Code/Pawsey/1. Initial Analysis/oxford_data/train_images.npy\", allow_pickle=True)\n",
    "\n",
    "test_gray_images = [cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in test_colour_images]\n",
    "train_gray_images = [cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in train_colour_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in names:\n",
    "test_names = np.load(\"/home/sean/Code/Pawsey/1. Initial Analysis/oxford_data/test_names.npy\", allow_pickle=True)\n",
    "train_names = np.load(\"/home/sean/Code/Pawsey/1. Initial Analysis/oxford_data/train_names.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SIFT Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the amount of words you want\n",
    "n_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing test SIFT features...\n",
      "Percentage Completed: 100%\n",
      "\n",
      "Computing train SIFT features...\n",
      "Percentage Completed: 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4446/2309145608.py:28: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  all_descriptors = np.vstack(i for i in stack)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustering Descriptors...\n",
      "Time Elapsed: 0.04 min\n",
      "\n",
      "Computing test BoVW...\n",
      "(1/2) Percentage Completed: 100%\n",
      "(2/2) Percentage Completed: 100%\n",
      "\n",
      "Computing train BoVW...\n",
      "(1/2) Percentage Completed: 100%\n",
      "(2/2) Percentage Completed: 100%\n"
     ]
    }
   ],
   "source": [
    "test_bovw, train_bovw = compute_SIFT(test_gray_images, train_gray_images, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=256 must be between 0 and min(n_samples, n_features)=100 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17643/1493668085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# can apply PCA here (256 for best mAP)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_bovw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bovw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bovw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_bovw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_17643/1342333603.py\u001b[0m in \u001b[0;36mpca\u001b[0;34m(trn_features, val_features, dim, print_opt)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# PCA Dimension reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Dimension reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    444\u001b[0m                                  \"if n_samples >= n_features\")\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0m\u001b[1;32m    447\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=256 must be between 0 and min(n_samples, n_features)=100 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# can apply PCA here (256 for best mAP)\n",
    "test_bovw1, train_bovw1 = pca(train_bovw, test_bovw, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Metrics...\n",
      "Percentage Complete: 100%\n",
      "mAP = 0.09853524550611947\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "print(\"\\nComputing Metrics...\")\n",
    "AP, precisionsatk = image_retrieval_k(train_bovw, test_bovw, train_names, test_names, train_colour_images, test_colour_images, k=10, view_option=0, border_size=20)\n",
    "\n",
    "# Display mAP\n",
    "mAP = np.average(AP)\n",
    "print(\"\\nmAP =\", mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'magdalen',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'pitt_rivers',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'balliol',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'balliol',\n",
       " 'magdalen',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'balliol',\n",
       " 'all_souls',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'ashmolean',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'balliol',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'magdalen',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'hertford',\n",
       " 'hertford',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'all_souls',\n",
       " 'magdalen',\n",
       " 'magdalen',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'magdalen',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'all_souls',\n",
       " 'christ_church',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'all_souls',\n",
       " 'ashmolean',\n",
       " 'all_souls',\n",
       " 'magdalen',\n",
       " 'ashmolean',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'balliol',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'cornmarket',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'magdalen',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'ashmolean',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'cornmarket',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'keble',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'ashmolean',\n",
       " 'cornmarket',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'christ_church',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'balliol',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'christ_church',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'hertford',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'all_souls',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'hertford',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'bodleian',\n",
       " 'magdalen',\n",
       " 'hertford',\n",
       " 'magdalen',\n",
       " 'magdalen',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'ashmolean',\n",
       " 'hertford',\n",
       " 'hertford',\n",
       " 'christ_church',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'radcliffe_camera',\n",
       " 'magdalen',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'hertford',\n",
       " 'radcliffe_camera',\n",
       " 'bodleian',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls',\n",
       " 'all_souls',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'radcliffe_camera',\n",
       " 'all_souls']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
