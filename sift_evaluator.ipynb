{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sift Evaluator\n",
    "\n",
    "The objectives of this notebook are to:\n",
    "\n",
    "- Define functions that query the data based on different parameters (distance metric, transformations?)\n",
    "- Define functions to evaluate the truth of each returned query parameter\n",
    "- Define functions to calculate mAP and precision@k for the above output\n",
    "- Investigate the effects of different parameters on mAP, p@k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "# Functions\n",
    "____\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "import sklearn.metrics.pairwise\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_query(query_image, query_target, metric_function = sklearn.metrics.pairwise.euclidean_distances):\n",
    "    \"\"\"Return the indexes of the query_target images, arranged in ascending euclidean distance as compared to the query image\"\"\"\n",
    "    \n",
    "    query = query_image.reshape((1, -1))\n",
    "    D = metric_function(query_target, query).squeeze()\n",
    "    index = np.argsort(D)\n",
    "\n",
    "    return(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Query to Truth Value Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_results_to_truth_values(query_image_building, query_results, image_names):\n",
    "    \"\"\"Convert the index results of a query to an array of booleans corresponding to whether the correct image was retrieved.\"\"\"\n",
    "    return([query_image_building == image_names[index] for index in query_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "### Truth Value Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(truth_values, k, warnings=True):\n",
    "    \"\"\"Return proportions of true values in the first k elements.\n",
    "    If warnings=True and all true values occur before the kth element, raise an error and print the value at k and the value at the last true value.\"\"\"\n",
    "    p_at_k = truth_values[:k].count(True) / k\n",
    "\n",
    "    ## Complete code to output p at k, p at last value\n",
    "    if warnings:\n",
    "        if k < len(truth_values):\n",
    "            if truth_values[k:].count(True) == 0:\n",
    "                raise ValueError(\"All true values are before the first k values\")\n",
    "    \n",
    "    return(p_at_k)\n",
    "\n",
    "\n",
    "## Create a more computationally efficient version using true positives, false positives?\n",
    "def average_precision(truth_values):\n",
    "    \"\"\"Given a boolean input of whether returned query values are correct or false, return the average precision.\n",
    "    e.g. average_precision([True, True, False, True]) ~ 0.85\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    for (index, val) in enumerate(truth_values):\n",
    "        if val: # == True\n",
    "            precisions.append(truth_values[:index + 1].count(True) / (index + 1))      \n",
    "\n",
    "    return(np.mean(precisions))\n",
    "\n",
    "#tbd\n",
    "def mean_average_precision():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_averageprecision (__main__.TestMetrics) ... ok\n",
      "test_precision_at_k (__main__.TestMetrics) ... ok\n",
      "test_basicquery (__main__.TestQuery) ... ok\n",
      "test_queryresultstotruthvalues (__main__.TestTruthValues) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fcfcfa2bb20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestQuery(unittest.TestCase):\n",
    "\n",
    "    def test_basicquery(self):\n",
    "        test_query = np.array([0,0,0,0])\n",
    "        test_query_target = pd.DataFrame(data={\"a\" : [4,0,0,0],\n",
    "                             \"b\" : [0,1,2,0],\n",
    "                             \"c\" : [0,0,0,0],\n",
    "                             \"d\" : [0,0,0,6]})\n",
    "        self.assertTrue(np.allclose(basic_query(test_query, test_query_target), [1,2,0,3]))\n",
    "\n",
    "class TestTruthValues(unittest.TestCase):\n",
    "\n",
    "    def test_queryresultstotruthvalues(self):\n",
    "        test_query_image_building = \"A\"\n",
    "        test_query_results = [0,4,3,2,1,5,6]\n",
    "        test_image_names = [\"A\", \"B\", \"C\", \"D\", \"A\", \"A\", \"D\"]\n",
    "        results = query_results_to_truth_values(test_query_image_building, test_query_results, test_image_names)\n",
    "        self.assertTrue(np.array_equal(results, [True, True, False, False, False, True, False]))\n",
    "\n",
    "class TestMetrics(unittest.TestCase):\n",
    "\n",
    "    def test_precision_at_k(self):\n",
    "        self.assertEqual(precision_at_k([True,False,True, True],4), 0.75)\n",
    "        self.assertEqual(precision_at_k([True, False, True, False, True], 2), 0.5)\n",
    "\n",
    "    def test_averageprecision(self):\n",
    "        self.assertAlmostEqual(average_precision([True, False, True, True]), np.mean([1,2/3,3/4]))\n",
    "        self.assertAlmostEqual(average_precision([False, False, True, False, True]), np.mean([1/3,2/5]))\n",
    "    \n",
    "    # def test_meanaverageprecision(self)\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "# Evaluate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314357</td>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.288328</td>\n",
       "      <td>0.203231</td>\n",
       "      <td>0.247281</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.269306</td>\n",
       "      <td>0.321365</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.422480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323421</td>\n",
       "      <td>0.171378</td>\n",
       "      <td>0.285630</td>\n",
       "      <td>0.188076</td>\n",
       "      <td>0.267174</td>\n",
       "      <td>0.565107</td>\n",
       "      <td>0.249596</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.323421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382649</td>\n",
       "      <td>0.202579</td>\n",
       "      <td>0.280109</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.217585</td>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.335131</td>\n",
       "      <td>0.290113</td>\n",
       "      <td>0.380148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298072</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.276083</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.305401</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.309066</td>\n",
       "      <td>0.285856</td>\n",
       "      <td>0.273640</td>\n",
       "      <td>0.316396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.148814</td>\n",
       "      <td>0.304391</td>\n",
       "      <td>0.257042</td>\n",
       "      <td>0.228632</td>\n",
       "      <td>0.274629</td>\n",
       "      <td>0.247572</td>\n",
       "      <td>0.403149</td>\n",
       "      <td>0.347683</td>\n",
       "      <td>0.482968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.251836</td>\n",
       "      <td>0.334334</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.258349</td>\n",
       "      <td>0.492817</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.329992</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.360386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.237406</td>\n",
       "      <td>0.221256</td>\n",
       "      <td>0.224486</td>\n",
       "      <td>0.179266</td>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.197031</td>\n",
       "      <td>0.332153</td>\n",
       "      <td>0.299315</td>\n",
       "      <td>0.654617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.352977</td>\n",
       "      <td>0.186982</td>\n",
       "      <td>0.301461</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.233728</td>\n",
       "      <td>0.417848</td>\n",
       "      <td>0.262348</td>\n",
       "      <td>0.374919</td>\n",
       "      <td>0.237544</td>\n",
       "      <td>0.427388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.222150</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.283858</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>0.235520</td>\n",
       "      <td>0.376421</td>\n",
       "      <td>0.280773</td>\n",
       "      <td>0.266374</td>\n",
       "      <td>0.401104</td>\n",
       "      <td>0.404190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.412206</td>\n",
       "      <td>0.120135</td>\n",
       "      <td>0.177447</td>\n",
       "      <td>0.445821</td>\n",
       "      <td>0.197286</td>\n",
       "      <td>0.162568</td>\n",
       "      <td>0.269477</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.449128</td>\n",
       "      <td>0.269477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.314357  0.166189  0.288328  0.203231  0.247281  0.408464  0.269306   \n",
       "1    0.323421  0.171378  0.285630  0.188076  0.267174  0.565107  0.249596   \n",
       "2    0.382649  0.202579  0.280109  0.296366  0.217585  0.437671  0.257600   \n",
       "3    0.298072  0.195457  0.276083  0.195457  0.305401  0.559495  0.309066   \n",
       "4    0.336860  0.148814  0.304391  0.257042  0.228632  0.274629  0.247572   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "562  0.321308  0.251836  0.334334  0.238810  0.258349  0.492817  0.240981   \n",
       "563  0.312773  0.237406  0.221256  0.224486  0.179266  0.216949  0.197031   \n",
       "564  0.352977  0.186982  0.301461  0.268072  0.233728  0.417848  0.262348   \n",
       "565  0.222150  0.391848  0.283858  0.212894  0.235520  0.376421  0.280773   \n",
       "566  0.412206  0.120135  0.177447  0.445821  0.197286  0.162568  0.269477   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.321365  0.408464  0.422480  \n",
       "1    0.313753  0.304965  0.323421  \n",
       "2    0.335131  0.290113  0.380148  \n",
       "3    0.285856  0.273640  0.316396  \n",
       "4    0.403149  0.347683  0.482968  \n",
       "..        ...       ...       ...  \n",
       "562  0.329992  0.240981  0.360386  \n",
       "563  0.332153  0.299315  0.654617  \n",
       "564  0.374919  0.237544  0.427388  \n",
       "565  0.266374  0.401104  0.404190  \n",
       "566  0.416063  0.449128  0.269477  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"/home/sean/Code/Pawsey/oxford_data/\"\n",
    "\n",
    "def load_data(name):\n",
    "    \"\"\"Returns a dictionary of attributes and 1 of features for train or test data\"\"\"\n",
    "\n",
    "    attributes = {}\n",
    "    \n",
    "    for img_att in [\"names\", \"pixels\", \"images\"]:\n",
    "        attributes[img_att] = np.load(BASE_DIR + name + \"_\" + img_att + \".npy\", allow_pickle=True)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    os.chdir(BASE_DIR + \"NPY files for BoVW/\")\n",
    "    for bovw_size in os.listdir():\n",
    "        features[bovw_size] = pd.DataFrame(np.load(bovw_size + \"/BoW_\" + name.capitalize() + \".npy\"))\n",
    "    \n",
    "    return(attributes, features)\n",
    "\n",
    "(test_attributes, test_features) = load_data(\"test\")\n",
    "(train_attributes, train_features) = load_data(\"train\")\n",
    "train_features[\"bovw files for 10 Words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 55 features, but Normalizer is expecting 567 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3950/967683867.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcolumn_normaliser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_feature_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbovw_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_normaliser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtest_feature_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbovw_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_normaliser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtrain_feature_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bovw files for 10 Words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bovw files for 10 Words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \"\"\"\n\u001b[1;32m   2046\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2048\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 55 features, but Normalizer is expecting 567 features as input."
     ]
    }
   ],
   "source": [
    "## double check this code, it should normalise features but unsure?\n",
    "\n",
    "# normalising the columns\n",
    "train_feature_norm = {}\n",
    "test_feature_norm = {}\n",
    "\n",
    "# normalising the rows\n",
    "train_vector_norm = {}\n",
    "test_vector_norm = {}\n",
    "\n",
    "for bovw_size in train_features.keys():\n",
    "    train = train_features[bovw_size]\n",
    "    test = test_features[bovw_size]\n",
    "\n",
    "    row_normaliser = sklearn.preprocessing.Normalizer().fit(train)\n",
    "    train_vector_norm[bovw_size] = row_normaliser.transform(train)\n",
    "    test_vector_norm[bovw_size] = row_normaliser.transform(test)\n",
    "\n",
    "    # rotate dataframes to normalise by column\n",
    "    temp_train = train.T\n",
    "    temp_test = test.T\n",
    "    column_normaliser = sklearn.preprocessing.Normalizer().fit(temp_train)\n",
    "    train_feature_norm[bovw_size] = column_normaliser.transform(temp_train).T\n",
    "    test_feature_norm[bovw_size] = column_normaliser.transform(temp_test).T\n",
    "\n",
    "train_feature_norm([\"bovw files for 10 Words\"]) == sklearn.preprocessing.normalize(train_features[\"bovw files for 10 Words\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ],\n",
       "       [-0.99503719, -0.09950372]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.DataFrame({1:[1,-10], 2:[0,-1]})\n",
    "normaliser = sklearn.preprocessing.Normalizer().fit(dat)\n",
    "normaliser.transform(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1     2\n",
       "0  True  True\n",
       "1  True  True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.T.T == dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.042749</td>\n",
       "      <td>0.027550</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.046413</td>\n",
       "      <td>0.038791</td>\n",
       "      <td>0.032862</td>\n",
       "      <td>0.054076</td>\n",
       "      <td>0.043833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036776</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.042349</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>0.035952</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>0.033555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043510</td>\n",
       "      <td>0.034131</td>\n",
       "      <td>0.041531</td>\n",
       "      <td>0.040176</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>0.037105</td>\n",
       "      <td>0.034269</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>0.039441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033893</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.040934</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.029231</td>\n",
       "      <td>0.036226</td>\n",
       "      <td>0.032826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038304</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>0.045131</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.036952</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.035660</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.046029</td>\n",
       "      <td>0.050108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.036535</td>\n",
       "      <td>0.042430</td>\n",
       "      <td>0.049570</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>0.041754</td>\n",
       "      <td>0.055998</td>\n",
       "      <td>0.034711</td>\n",
       "      <td>0.033744</td>\n",
       "      <td>0.031903</td>\n",
       "      <td>0.037390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.035565</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.033965</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>0.067917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.031503</td>\n",
       "      <td>0.044696</td>\n",
       "      <td>0.036340</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.047480</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.044342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.025260</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.028860</td>\n",
       "      <td>0.038065</td>\n",
       "      <td>0.042772</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.053101</td>\n",
       "      <td>0.041935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.046871</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.026309</td>\n",
       "      <td>0.060436</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.038816</td>\n",
       "      <td>0.042545</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.027958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.035745  0.028000  0.042749  0.027550  0.039966  0.046413  0.038791   \n",
       "1    0.036776  0.028874  0.042349  0.025496  0.043181  0.064213  0.035952   \n",
       "2    0.043510  0.034131  0.041531  0.040176  0.035166  0.049732  0.037105   \n",
       "3    0.033893  0.032931  0.040934  0.026496  0.049359  0.063575  0.044518   \n",
       "4    0.038304  0.025072  0.045131  0.034845  0.036952  0.031206  0.035660   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "562  0.036535  0.042430  0.049570  0.032374  0.041754  0.055998  0.034711   \n",
       "563  0.035565  0.039999  0.032805  0.030432  0.028973  0.024652  0.028380   \n",
       "564  0.040136  0.031503  0.044696  0.036340  0.037775  0.047480  0.037789   \n",
       "565  0.025260  0.066019  0.042086  0.028860  0.038065  0.042772  0.040443   \n",
       "566  0.046871  0.020241  0.026309  0.060436  0.031885  0.018472  0.038816   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.032862  0.054076  0.043833  \n",
       "1    0.032083  0.040374  0.033555  \n",
       "2    0.034269  0.038407  0.039441  \n",
       "3    0.029231  0.036226  0.032826  \n",
       "4    0.041225  0.046029  0.050108  \n",
       "..        ...       ...       ...  \n",
       "562  0.033744  0.031903  0.037390  \n",
       "563  0.033965  0.039626  0.067917  \n",
       "564  0.038338  0.031448  0.044342  \n",
       "565  0.027239  0.053101  0.041935  \n",
       "566  0.042545  0.059459  0.027958  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalising the columns\n",
    "train_feature_norm = {}\n",
    "test_feature_norm = {}\n",
    "\n",
    "# normalising the rows\n",
    "train_vector_norm = {}\n",
    "test_vector_norm = {}\n",
    "\n",
    "for (bovw_size, features) in train_features.items():\n",
    "    full_df = pd.concat([train_features[bovw_size], test_features[bovw_size]], ignore_index=True)\n",
    "\n",
    "    feature_norm = sklearn.preprocessing.normalize(full_df, axis=0)\n",
    "    train_feature_norm[bovw_size] = pd.DataFrame(feature_norm[:567,:])\n",
    "    test_feature_norm[bovw_size] = pd.DataFrame(feature_norm[567:,:])\n",
    "\n",
    "    vector_norm = sklearn.preprocessing.normalize(full_df, axis=1)\n",
    "    train_vector_norm[bovw_size] = pd.DataFrame(vector_norm[:567,:])\n",
    "    test_vector_norm[bovw_size] = pd.DataFrame(vector_norm[567:,:])\n",
    "\n",
    "## Advanced method for easily handling multiple transformations, currently not working\n",
    "\n",
    "# train_transformed = {}\n",
    "# test_transformed = {}\n",
    "\n",
    "# for bovw_size in train_features.keys():\n",
    "#     full_df = pd.concat([train_features[bovw_size], test_features[bovw_size]], ignore_index = True)\n",
    "\n",
    "#     transformed_dfs = {\"Vector normalised\" : sklearn.preprocessing.normalize(full_df, axis = 1),\n",
    "#                            \"Feature normalised\" : sklearn.preprocessing.normalize(full_df, axis = 0)}\n",
    "    \n",
    "#     for transformation_name in transformed_dfs.keys():\n",
    "#         train_transformed[transformation_name] = {}\n",
    "#         test_transformed[transformation_name] = {}\n",
    "\n",
    "#     for (transformation_name, transformed_df) in transformed_dfs.items():\n",
    "#         train_transformed[transformation_name][bovw_size] = transformed_df[:567,:]\n",
    "#         test_transformed[transformation_name][bovw_size] = transformed_df[567:,:]\n",
    "\n",
    "train_feature_norm[\"bovw files for 10 Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314357</td>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.288328</td>\n",
       "      <td>0.203231</td>\n",
       "      <td>0.247281</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.269306</td>\n",
       "      <td>0.321365</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.422480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323421</td>\n",
       "      <td>0.171378</td>\n",
       "      <td>0.285630</td>\n",
       "      <td>0.188076</td>\n",
       "      <td>0.267174</td>\n",
       "      <td>0.565107</td>\n",
       "      <td>0.249596</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.323421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382649</td>\n",
       "      <td>0.202579</td>\n",
       "      <td>0.280109</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.217585</td>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.335131</td>\n",
       "      <td>0.290113</td>\n",
       "      <td>0.380148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298072</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.276083</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.305401</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.309066</td>\n",
       "      <td>0.285856</td>\n",
       "      <td>0.273640</td>\n",
       "      <td>0.316396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.148814</td>\n",
       "      <td>0.304391</td>\n",
       "      <td>0.257042</td>\n",
       "      <td>0.228632</td>\n",
       "      <td>0.274629</td>\n",
       "      <td>0.247572</td>\n",
       "      <td>0.403149</td>\n",
       "      <td>0.347683</td>\n",
       "      <td>0.482968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.251836</td>\n",
       "      <td>0.334334</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.258349</td>\n",
       "      <td>0.492817</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.329992</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.360386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.237406</td>\n",
       "      <td>0.221256</td>\n",
       "      <td>0.224486</td>\n",
       "      <td>0.179266</td>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.197031</td>\n",
       "      <td>0.332153</td>\n",
       "      <td>0.299315</td>\n",
       "      <td>0.654617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.352977</td>\n",
       "      <td>0.186982</td>\n",
       "      <td>0.301461</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.233728</td>\n",
       "      <td>0.417848</td>\n",
       "      <td>0.262348</td>\n",
       "      <td>0.374919</td>\n",
       "      <td>0.237544</td>\n",
       "      <td>0.427388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.222150</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.283858</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>0.235520</td>\n",
       "      <td>0.376421</td>\n",
       "      <td>0.280773</td>\n",
       "      <td>0.266374</td>\n",
       "      <td>0.401104</td>\n",
       "      <td>0.404190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.412206</td>\n",
       "      <td>0.120135</td>\n",
       "      <td>0.177447</td>\n",
       "      <td>0.445821</td>\n",
       "      <td>0.197286</td>\n",
       "      <td>0.162568</td>\n",
       "      <td>0.269477</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.449128</td>\n",
       "      <td>0.269477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.314357  0.166189  0.288328  0.203231  0.247281  0.408464  0.269306   \n",
       "1    0.323421  0.171378  0.285630  0.188076  0.267174  0.565107  0.249596   \n",
       "2    0.382649  0.202579  0.280109  0.296366  0.217585  0.437671  0.257600   \n",
       "3    0.298072  0.195457  0.276083  0.195457  0.305401  0.559495  0.309066   \n",
       "4    0.336860  0.148814  0.304391  0.257042  0.228632  0.274629  0.247572   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "562  0.321308  0.251836  0.334334  0.238810  0.258349  0.492817  0.240981   \n",
       "563  0.312773  0.237406  0.221256  0.224486  0.179266  0.216949  0.197031   \n",
       "564  0.352977  0.186982  0.301461  0.268072  0.233728  0.417848  0.262348   \n",
       "565  0.222150  0.391848  0.283858  0.212894  0.235520  0.376421  0.280773   \n",
       "566  0.412206  0.120135  0.177447  0.445821  0.197286  0.162568  0.269477   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.321365  0.408464  0.422480  \n",
       "1    0.313753  0.304965  0.323421  \n",
       "2    0.335131  0.290113  0.380148  \n",
       "3    0.285856  0.273640  0.316396  \n",
       "4    0.403149  0.347683  0.482968  \n",
       "..        ...       ...       ...  \n",
       "562  0.329992  0.240981  0.360386  \n",
       "563  0.332153  0.299315  0.654617  \n",
       "564  0.374919  0.237544  0.427388  \n",
       "565  0.266374  0.401104  0.404190  \n",
       "566  0.416063  0.449128  0.269477  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[\"bovw files for 10 Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_metrics = {\"euclidean\" : sklearn.metrics.pairwise.euclidean_distances,\n",
    "           \"cosine\" : sklearn.metrics.pairwise.cosine_distances,\n",
    "           \"manhattan\" :sklearn.metrics.pairwise.manhattan_distances,\n",
    "           \"nan_euclidean\" : sklearn.metrics.pairwise.nan_euclidean_distances}\n",
    "data_sets = {\"raw\" : (train_features, test_features),\n",
    "             \"vector_normalised\" : (train_vector_norm, test_vector_norm),\n",
    "             \"feature_normalised\" : (train_feature_norm, train_vector_norm)}\n",
    "\n",
    "def mean_average_precision(train_features, test_features, train_names, test_names, distance_metric):\n",
    "    \"\"\"descriptive docstring do map yeah\"\"\"\n",
    "    average_precisions = []\n",
    "    \n",
    "    for (test_feature, test_feature_name) in zip(test_features.iterrows(), test_names):\n",
    "        features_as_array = test_feature[1].values # extract the values for the iterrows row object\n",
    "        query_results = basic_query(features_as_array, train_features, distance_metric)\n",
    "        truth_values = query_results_to_truth_values(test_feature_name, query_results, train_names)\n",
    "        average_precisions.append(average_precision(truth_values))\n",
    "    \n",
    "    return(np.mean(average_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2846602906055916"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(train_features = train_features[\"bovw files for 10 Words\"],\n",
    "                       test_features = test_features[\"bovw files for 10 Words\"],\n",
    "                       train_names = train_attributes[\"names\"],\n",
    "                       test_names = test_attributes[\"names\"],\n",
    "                       distance_metric = sklearn.metrics.pairwise.euclidean_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean raw bovw files for 10000 Words : 0.5160431683671248\n",
      "euclidean raw bovw files for 10 Words : 0.2846602906055916\n",
      "euclidean raw bovw files for 100 Words : 0.3836962289612868\n",
      "euclidean raw bovw files for 20000 Words : 0.5679781603977279\n",
      "euclidean raw bovw files for 100000 Words : 0.6682471101801445\n",
      "euclidean raw bovw files for 1000 Words : 0.4096111116568395\n",
      "euclidean raw bovw files for 50000 Words : 0.6198841133826765\n",
      "euclidean vector_normalised bovw files for 10000 Words : 0.5160431683671248\n",
      "euclidean vector_normalised bovw files for 10 Words : 0.2846602906055916\n",
      "euclidean vector_normalised bovw files for 100 Words : 0.3836962289612868\n",
      "euclidean vector_normalised bovw files for 20000 Words : 0.5679781603977279\n",
      "euclidean vector_normalised bovw files for 100000 Words : 0.6682471101801445\n",
      "euclidean vector_normalised bovw files for 1000 Words : 0.4096111116568395\n",
      "euclidean vector_normalised bovw files for 50000 Words : 0.6198841133826765\n",
      "euclidean feature_normalised bovw files for 10000 Words : 0.1187179102679966\n",
      "euclidean feature_normalised bovw files for 10 Words : 0.1098687174293215\n",
      "euclidean feature_normalised bovw files for 100 Words : 0.11531995703982015\n",
      "euclidean feature_normalised bovw files for 20000 Words : 0.11708292314394053\n",
      "euclidean feature_normalised bovw files for 100000 Words : 0.12299252627951951\n",
      "euclidean feature_normalised bovw files for 1000 Words : 0.11116747513594802\n",
      "euclidean feature_normalised bovw files for 50000 Words : 0.12362256974043537\n",
      "cosine raw bovw files for 10000 Words : 0.5160431683671248\n",
      "cosine raw bovw files for 10 Words : 0.2846602906055916\n",
      "cosine raw bovw files for 100 Words : 0.3836962289612868\n",
      "cosine raw bovw files for 20000 Words : 0.5679781603977279\n",
      "cosine raw bovw files for 100000 Words : 0.6682471101801445\n",
      "cosine raw bovw files for 1000 Words : 0.4096111116568395\n",
      "cosine raw bovw files for 50000 Words : 0.6198841133826765\n",
      "cosine vector_normalised bovw files for 10000 Words : 0.5160431683671248\n",
      "cosine vector_normalised bovw files for 10 Words : 0.2846602906055916\n",
      "cosine vector_normalised bovw files for 100 Words : 0.3836962289612868\n",
      "cosine vector_normalised bovw files for 20000 Words : 0.5679781603977279\n",
      "cosine vector_normalised bovw files for 100000 Words : 0.6682471101801445\n",
      "cosine vector_normalised bovw files for 1000 Words : 0.4096111116568395\n",
      "cosine vector_normalised bovw files for 50000 Words : 0.6198841133826765\n",
      "cosine feature_normalised bovw files for 10000 Words : 0.12721748142865416\n",
      "cosine feature_normalised bovw files for 10 Words : 0.10834806621616948\n",
      "cosine feature_normalised bovw files for 100 Words : 0.1172355538169111\n",
      "cosine feature_normalised bovw files for 20000 Words : 0.12986295218509766\n",
      "cosine feature_normalised bovw files for 100000 Words : 0.12821524354813957\n",
      "cosine feature_normalised bovw files for 1000 Words : 0.10975839554307601\n",
      "cosine feature_normalised bovw files for 50000 Words : 0.13067980413839797\n",
      "manhattan raw bovw files for 10000 Words : 0.31391666271372104\n",
      "manhattan raw bovw files for 10 Words : 0.28016695234740613\n",
      "manhattan raw bovw files for 100 Words : 0.41987751669050827\n",
      "manhattan raw bovw files for 20000 Words : 0.28554885938607827\n",
      "manhattan raw bovw files for 100000 Words : 0.23436251972209132\n",
      "manhattan raw bovw files for 1000 Words : 0.45417839082446715\n",
      "manhattan raw bovw files for 50000 Words : 0.2627765163004305\n",
      "manhattan vector_normalised bovw files for 10000 Words : 0.31391666271372104\n",
      "manhattan vector_normalised bovw files for 10 Words : 0.28016695234740613\n",
      "manhattan vector_normalised bovw files for 100 Words : 0.41987751669050827\n",
      "manhattan vector_normalised bovw files for 20000 Words : 0.28554885938607827\n",
      "manhattan vector_normalised bovw files for 100000 Words : 0.23436251972209132\n",
      "manhattan vector_normalised bovw files for 1000 Words : 0.45417839082446715\n",
      "manhattan vector_normalised bovw files for 50000 Words : 0.2627765163004305\n",
      "manhattan feature_normalised bovw files for 10000 Words : 0.11976625094887537\n",
      "manhattan feature_normalised bovw files for 10 Words : 0.10244348793974557\n",
      "manhattan feature_normalised bovw files for 100 Words : 0.10820008715517543\n",
      "manhattan feature_normalised bovw files for 20000 Words : 0.12127181887525462\n",
      "manhattan feature_normalised bovw files for 100000 Words : 0.12321776545810721\n",
      "manhattan feature_normalised bovw files for 1000 Words : 0.11805791126815518\n",
      "manhattan feature_normalised bovw files for 50000 Words : 0.12561485785903012\n",
      "nan_euclidean raw bovw files for 10000 Words : 0.5160431683671248\n",
      "nan_euclidean raw bovw files for 10 Words : 0.2846602906055916\n",
      "nan_euclidean raw bovw files for 100 Words : 0.3836962289612868\n",
      "nan_euclidean raw bovw files for 20000 Words : 0.5679781603977279\n",
      "nan_euclidean raw bovw files for 100000 Words : 0.6682471101801445\n",
      "nan_euclidean raw bovw files for 1000 Words : 0.4096111116568395\n",
      "nan_euclidean raw bovw files for 50000 Words : 0.6198841133826765\n",
      "nan_euclidean vector_normalised bovw files for 10000 Words : 0.5160431683671248\n",
      "nan_euclidean vector_normalised bovw files for 10 Words : 0.2846602906055916\n",
      "nan_euclidean vector_normalised bovw files for 100 Words : 0.3836962289612868\n",
      "nan_euclidean vector_normalised bovw files for 20000 Words : 0.5679781603977279\n",
      "nan_euclidean vector_normalised bovw files for 100000 Words : 0.6682471101801445\n",
      "nan_euclidean vector_normalised bovw files for 1000 Words : 0.4096111116568395\n",
      "nan_euclidean vector_normalised bovw files for 50000 Words : 0.6198841133826765\n",
      "nan_euclidean feature_normalised bovw files for 10000 Words : 0.1187179102679966\n",
      "nan_euclidean feature_normalised bovw files for 10 Words : 0.1098687174293215\n",
      "nan_euclidean feature_normalised bovw files for 100 Words : 0.11531995703982015\n",
      "nan_euclidean feature_normalised bovw files for 20000 Words : 0.11708292314394053\n",
      "nan_euclidean feature_normalised bovw files for 100000 Words : 0.12299252627951951\n",
      "nan_euclidean feature_normalised bovw files for 1000 Words : 0.11116747513594802\n",
      "nan_euclidean feature_normalised bovw files for 50000 Words : 0.12362256974043537\n"
     ]
    }
   ],
   "source": [
    "for (metric_name, metric_function) in distance_metrics.items():\n",
    "    for (data_set_name, train_set_test_set) in data_sets.items():\n",
    "        train = train_set_test_set[0]\n",
    "        test = train_set_test_set[1]\n",
    "        for bovw_size in train.keys():\n",
    "            mean_ap = mean_average_precision(train[bovw_size], test[bovw_size], train_attributes[\"names\"],\n",
    "                                             test_attributes[\"names\"], metric_function)\n",
    "            print(\"{} {} {} : {}\".format(metric_name, data_set_name, bovw_size, mean_ap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.042749</td>\n",
       "      <td>0.027550</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.046413</td>\n",
       "      <td>0.038791</td>\n",
       "      <td>0.032862</td>\n",
       "      <td>0.054076</td>\n",
       "      <td>0.043833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036776</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.042349</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>0.035952</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>0.033555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043510</td>\n",
       "      <td>0.034131</td>\n",
       "      <td>0.041531</td>\n",
       "      <td>0.040176</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>0.037105</td>\n",
       "      <td>0.034269</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>0.039441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033893</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.040934</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.029231</td>\n",
       "      <td>0.036226</td>\n",
       "      <td>0.032826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038304</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>0.045131</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.036952</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.035660</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.046029</td>\n",
       "      <td>0.050108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.036535</td>\n",
       "      <td>0.042430</td>\n",
       "      <td>0.049570</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>0.041754</td>\n",
       "      <td>0.055998</td>\n",
       "      <td>0.034711</td>\n",
       "      <td>0.033744</td>\n",
       "      <td>0.031903</td>\n",
       "      <td>0.037390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.035565</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.033965</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>0.067917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.031503</td>\n",
       "      <td>0.044696</td>\n",
       "      <td>0.036340</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.047480</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.044342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.025260</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.028860</td>\n",
       "      <td>0.038065</td>\n",
       "      <td>0.042772</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.053101</td>\n",
       "      <td>0.041935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.046871</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.026309</td>\n",
       "      <td>0.060436</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.038816</td>\n",
       "      <td>0.042545</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.027958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.035745  0.028000  0.042749  0.027550  0.039966  0.046413  0.038791   \n",
       "1    0.036776  0.028874  0.042349  0.025496  0.043181  0.064213  0.035952   \n",
       "2    0.043510  0.034131  0.041531  0.040176  0.035166  0.049732  0.037105   \n",
       "3    0.033893  0.032931  0.040934  0.026496  0.049359  0.063575  0.044518   \n",
       "4    0.038304  0.025072  0.045131  0.034845  0.036952  0.031206  0.035660   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "562  0.036535  0.042430  0.049570  0.032374  0.041754  0.055998  0.034711   \n",
       "563  0.035565  0.039999  0.032805  0.030432  0.028973  0.024652  0.028380   \n",
       "564  0.040136  0.031503  0.044696  0.036340  0.037775  0.047480  0.037789   \n",
       "565  0.025260  0.066019  0.042086  0.028860  0.038065  0.042772  0.040443   \n",
       "566  0.046871  0.020241  0.026309  0.060436  0.031885  0.018472  0.038816   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.032862  0.054076  0.043833  \n",
       "1    0.032083  0.040374  0.033555  \n",
       "2    0.034269  0.038407  0.039441  \n",
       "3    0.029231  0.036226  0.032826  \n",
       "4    0.041225  0.046029  0.050108  \n",
       "..        ...       ...       ...  \n",
       "562  0.033744  0.031903  0.037390  \n",
       "563  0.033965  0.039626  0.067917  \n",
       "564  0.038338  0.031448  0.044342  \n",
       "565  0.027239  0.053101  0.041935  \n",
       "566  0.042545  0.059459  0.027958  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_feature_norm[\"bovw files for 10 Words\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
