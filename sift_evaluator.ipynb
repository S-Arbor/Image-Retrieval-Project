{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sift Evaluator\n",
    "\n",
    "The objectives of this notebook are to:\n",
    "\n",
    "- Define functions that query the data based on different parameters (distance metric, transformations?)\n",
    "- Define functions to evaluate the truth of each returned query parameter\n",
    "- Define functions to calculate mAP and precision@k for the above output\n",
    "- Investigate the effects of different parameters on mAP, p@k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "# Functions\n",
    "____\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "import sklearn.metrics.pairwise\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_query(query_image, query_target, metric_function = sklearn.metrics.pairwise.euclidean_distances):\n",
    "    \"\"\"Return the indexes of the query_target images, arranged in ascending euclidean distance as compared to the query image\"\"\"\n",
    "    \n",
    "    # copy pasted code to investigate\n",
    "    query = query_image.reshape((1, -1))\n",
    "    D = metric_function(query_target, query).squeeze()\n",
    "    index = np.argsort(D)\n",
    "\n",
    "    return(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Query to Truth Value Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_results_to_truth_values(query_image_building, query_results, image_names):\n",
    "    \"\"\"Convert the index results of a query to an array of booleans corresponding to whether the correct image was retrieved.\"\"\"\n",
    "    return([query_image_building == image_names[index] for index in query_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "### Truth Value Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(truth_values, k, warnings=True):\n",
    "    \"\"\"Return proportions of true values in the first k elements.\n",
    "    If warnings=True and all true values occur before the kth element, raise an error and print the value at k and the value at the last true value.\"\"\"\n",
    "    p_at_k = truth_values[:k].count(True) / k\n",
    "\n",
    "    ## Complete code to output p at k, p at last value\n",
    "    if warnings:\n",
    "        if k < len(truth_values):\n",
    "            if truth_values[k:].count(True) == 0:\n",
    "                raise ValueError(\"All true values are before the first k values\")\n",
    "    \n",
    "    return(p_at_k)\n",
    "\n",
    "\n",
    "## Create a more computationally efficient version using true positives, false positives?\n",
    "def average_precision(truth_values):\n",
    "    \"\"\"Given a boolean input of whether returned query values are correct or false, return the average precision.\n",
    "    e.g. average_precision([True, True, False, True]) ~ 0.85\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    for (index, val) in enumerate(truth_values):\n",
    "        if val: # == True\n",
    "            precisions.append(truth_values[:index + 1].count(True) / (index + 1))      \n",
    "\n",
    "    return(np.mean(precisions))\n",
    "\n",
    "#tbd\n",
    "def mean_average_precision():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_averageprecision (__main__.TestMetrics) ... ok\n",
      "test_precision_at_k (__main__.TestMetrics) ... ok\n",
      "test_basicquery (__main__.TestQuery) ... ok\n",
      "test_queryresultstotruthvalues (__main__.TestTruthValues) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fb426dc12e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestQuery(unittest.TestCase):\n",
    "\n",
    "    def test_basicquery(self):\n",
    "        test_query = np.array([0,0,0,0])\n",
    "        test_query_target = pd.DataFrame(data={\"a\" : [4,0,0,0],\n",
    "                             \"b\" : [0,1,2,0],\n",
    "                             \"c\" : [0,0,0,0],\n",
    "                             \"d\" : [0,0,0,6]})\n",
    "        self.assertTrue(np.allclose(basic_query(test_query, test_query_target), [1,2,0,3]))\n",
    "\n",
    "class TestTruthValues(unittest.TestCase):\n",
    "\n",
    "    def test_queryresultstotruthvalues(self):\n",
    "        test_query_image_building = \"A\"\n",
    "        test_query_results = [0,4,3,2,1,5,6]\n",
    "        test_image_names = [\"A\", \"B\", \"C\", \"D\", \"A\", \"A\", \"D\"]\n",
    "        results = query_results_to_truth_values(test_query_image_building, test_query_results, test_image_names)\n",
    "        self.assertTrue(np.array_equal(results, [True, True, False, False, False, True, False]))\n",
    "\n",
    "class TestMetrics(unittest.TestCase):\n",
    "\n",
    "    def test_precision_at_k(self):\n",
    "        self.assertEqual(precision_at_k([True,False,True, True],4), 0.75)\n",
    "        self.assertEqual(precision_at_k([True, False, True, False, True], 2), 0.5)\n",
    "\n",
    "    def test_averageprecision(self):\n",
    "        self.assertAlmostEqual(average_precision([True, False, True, True]), np.mean([1,2/3,3/4]))\n",
    "        self.assertAlmostEqual(average_precision([False, False, True, False, True]), np.mean([1/3,2/5]))\n",
    "    \n",
    "    # def test_meanaverageprecision(self)\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "# Evaluate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314357</td>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.288328</td>\n",
       "      <td>0.203231</td>\n",
       "      <td>0.247281</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.269306</td>\n",
       "      <td>0.321365</td>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.422480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323421</td>\n",
       "      <td>0.171378</td>\n",
       "      <td>0.285630</td>\n",
       "      <td>0.188076</td>\n",
       "      <td>0.267174</td>\n",
       "      <td>0.565107</td>\n",
       "      <td>0.249596</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.323421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382649</td>\n",
       "      <td>0.202579</td>\n",
       "      <td>0.280109</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.217585</td>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.335131</td>\n",
       "      <td>0.290113</td>\n",
       "      <td>0.380148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298072</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.276083</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.305401</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.309066</td>\n",
       "      <td>0.285856</td>\n",
       "      <td>0.273640</td>\n",
       "      <td>0.316396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.148814</td>\n",
       "      <td>0.304391</td>\n",
       "      <td>0.257042</td>\n",
       "      <td>0.228632</td>\n",
       "      <td>0.274629</td>\n",
       "      <td>0.247572</td>\n",
       "      <td>0.403149</td>\n",
       "      <td>0.347683</td>\n",
       "      <td>0.482968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.251836</td>\n",
       "      <td>0.334334</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.258349</td>\n",
       "      <td>0.492817</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.329992</td>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.360386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.237406</td>\n",
       "      <td>0.221256</td>\n",
       "      <td>0.224486</td>\n",
       "      <td>0.179266</td>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.197031</td>\n",
       "      <td>0.332153</td>\n",
       "      <td>0.299315</td>\n",
       "      <td>0.654617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.352977</td>\n",
       "      <td>0.186982</td>\n",
       "      <td>0.301461</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.233728</td>\n",
       "      <td>0.417848</td>\n",
       "      <td>0.262348</td>\n",
       "      <td>0.374919</td>\n",
       "      <td>0.237544</td>\n",
       "      <td>0.427388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.222150</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.283858</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>0.235520</td>\n",
       "      <td>0.376421</td>\n",
       "      <td>0.280773</td>\n",
       "      <td>0.266374</td>\n",
       "      <td>0.401104</td>\n",
       "      <td>0.404190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.412206</td>\n",
       "      <td>0.120135</td>\n",
       "      <td>0.177447</td>\n",
       "      <td>0.445821</td>\n",
       "      <td>0.197286</td>\n",
       "      <td>0.162568</td>\n",
       "      <td>0.269477</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.449128</td>\n",
       "      <td>0.269477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.314357  0.166189  0.288328  0.203231  0.247281  0.408464  0.269306   \n",
       "1    0.323421  0.171378  0.285630  0.188076  0.267174  0.565107  0.249596   \n",
       "2    0.382649  0.202579  0.280109  0.296366  0.217585  0.437671  0.257600   \n",
       "3    0.298072  0.195457  0.276083  0.195457  0.305401  0.559495  0.309066   \n",
       "4    0.336860  0.148814  0.304391  0.257042  0.228632  0.274629  0.247572   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "562  0.321308  0.251836  0.334334  0.238810  0.258349  0.492817  0.240981   \n",
       "563  0.312773  0.237406  0.221256  0.224486  0.179266  0.216949  0.197031   \n",
       "564  0.352977  0.186982  0.301461  0.268072  0.233728  0.417848  0.262348   \n",
       "565  0.222150  0.391848  0.283858  0.212894  0.235520  0.376421  0.280773   \n",
       "566  0.412206  0.120135  0.177447  0.445821  0.197286  0.162568  0.269477   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.321365  0.408464  0.422480  \n",
       "1    0.313753  0.304965  0.323421  \n",
       "2    0.335131  0.290113  0.380148  \n",
       "3    0.285856  0.273640  0.316396  \n",
       "4    0.403149  0.347683  0.482968  \n",
       "..        ...       ...       ...  \n",
       "562  0.329992  0.240981  0.360386  \n",
       "563  0.332153  0.299315  0.654617  \n",
       "564  0.374919  0.237544  0.427388  \n",
       "565  0.266374  0.401104  0.404190  \n",
       "566  0.416063  0.449128  0.269477  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"/home/sean/Code/Pawsey/oxford_data/\"\n",
    "\n",
    "def load_data(name):\n",
    "    \"\"\"Returns a dictionary of attributes and 1 of features for train or test data\"\"\"\n",
    "\n",
    "    attributes = {}\n",
    "    \n",
    "    for img_att in [\"names\", \"pixels\", \"images\"]:\n",
    "        attributes[img_att] = np.load(BASE_DIR + name + \"_\" + img_att + \".npy\", allow_pickle=True)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    os.chdir(BASE_DIR + \"NPY files for BoVW/\")\n",
    "    for bovw_size in os.listdir():\n",
    "        features[bovw_size] = pd.DataFrame(np.load(bovw_size + \"/BoW_\" + name.capitalize() + \".npy\"))\n",
    "    \n",
    "    return(attributes, features)\n",
    "\n",
    "(test_attributes, test_features) = load_data(\"test\")\n",
    "(train_attributes, train_features) = load_data(\"train\")\n",
    "train_features[\"bovw files for 10 Words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31435731, 0.1661889 , 0.28832773, 0.203231  , 0.24728107,\n",
       "       0.40846428, 0.26930611, 0.32136528, 0.40846428, 0.42248021])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalising the columns\n",
    "train_feature_norm = {}\n",
    "test_feature_norm = {}\n",
    "\n",
    "# normalising the rows\n",
    "train_vector_norm = {}\n",
    "test_vector_norm = {}\n",
    "\n",
    "for (bovw_size, features) in train_features.items():\n",
    "    full_df = pd.concat([train_features[bovw_size], test_features[bovw_size]], ignore_index=True)\n",
    "\n",
    "    feature_norm = sklearn.preprocessing.normalize(full_df, axis=0)\n",
    "    train_feature_norm[bovw_size] = feature_norm[:567,:]\n",
    "    test_feature_norm[bovw_size] = feature_norm[:567,:]\n",
    "\n",
    "    vector_norm = sklearn.preprocessing.normalize(full_df, axis=1)\n",
    "    train_vector_norm[bovw_size] = vector_norm[:567,:]\n",
    "    test_vector_norm[bovw_size] = vector_norm[:567,:]\n",
    "\n",
    "## Advanced method for easily handling multiple transformations, currently not working\n",
    "\n",
    "# train_transformed = {}\n",
    "# test_transformed = {}\n",
    "\n",
    "# for bovw_size in train_features.keys():\n",
    "#     full_df = pd.concat([train_features[bovw_size], test_features[bovw_size]], ignore_index = True)\n",
    "\n",
    "#     transformed_dfs = {\"Vector normalised\" : sklearn.preprocessing.normalize(full_df, axis = 1),\n",
    "#                            \"Feature normalised\" : sklearn.preprocessing.normalize(full_df, axis = 0)}\n",
    "    \n",
    "#     for transformation_name in transformed_dfs.keys():\n",
    "#         train_transformed[transformation_name] = {}\n",
    "#         test_transformed[transformation_name] = {}\n",
    "\n",
    "#     for (transformation_name, transformed_df) in transformed_dfs.items():\n",
    "#         train_transformed[transformation_name][bovw_size] = transformed_df[:567,:]\n",
    "#         test_transformed[transformation_name][bovw_size] = transformed_df[567:,:]\n",
    "\n",
    "train_vector_norm[\"bovw files for 10 Words\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_metrics = {\"euclidean\" : sklearn.metrics.pairwise.euclidean_distances,\n",
    "           \"cosine\" : sklearn.metrics.pairwise.cosine_distances,\n",
    "           \"manhattan\" :sklearn.metrics.pairwise.manhattan_distances,\n",
    "           \"nan_euclidean\" : sklearn.metrics.pairwise.nan_euclidean_distances}\n",
    "data_sets = {\"raw\" : (train_features, test_features),\n",
    "             \"vector_normalised\" : (train_vector_norm, test_vector_norm),\n",
    "             \"feature_normalised\" : (train_feature_norm, train_vector_norm)}\n",
    "\n",
    "def mean_average_precision(train_features, test_features, train_names, test_names, distance_metric):\n",
    "    \"\"\"descriptive docstring do map yeah\"\"\"\n",
    "    average_precisions = []\n",
    "    \n",
    "    for (test_feature, test_feature_name) in zip(test_features, test_names):\n",
    "        print(test_feature)\n",
    "        query_results = basic_query(test_feature, train_features, distance_metric)\n",
    "        truth_values = query_results_to_truth_values(test_feature_name, query_results, train_names)\n",
    "        average_precisions.append(average_precision(truth_values))\n",
    "    \n",
    "    return(np.mean(average_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4400/598352683.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set_test_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbovw_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             mean_ap = mean_average_precision(train[bovw_size], test[bovw_size], train_attributes[\"names\"],\n\u001b[0m\u001b[1;32m      7\u001b[0m                                              test_attributes[\"names\"], metric_function)\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} {} {} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbovw_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_ap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4400/3195338510.py\u001b[0m in \u001b[0;36mmean_average_precision\u001b[0;34m(train_features, test_features, train_names, test_names, distance_metric)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feature_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mquery_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtruth_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_results_to_truth_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0maverage_precisions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4400/369447943.py\u001b[0m in \u001b[0;36mbasic_query\u001b[0;34m(query_image, query_target, metric_function)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# copy pasted code to investigate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "for (metric_name, metric_function) in distance_metrics.items():\n",
    "    for (data_set_name, train_set_test_set) in data_sets.items():\n",
    "        train = train_set_test_set[0]\n",
    "        test = train_set_test_set[1]\n",
    "        for bovw_size in train.keys():\n",
    "            mean_ap = mean_average_precision(train[bovw_size], test[bovw_size], train_attributes[\"names\"],\n",
    "                                             test_attributes[\"names\"], metric_function)\n",
    "            print(\"{} {} {} : {}\".format(metric_name, data_set_name, bovw_size, mean_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1389134486.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4400/1389134486.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for (a, (b, c) in data_sets.items():\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for (a, (b, c) in data_sets.items():\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
