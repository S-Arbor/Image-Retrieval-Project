{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calculate_average_precision(index, idx, train_names, test_names, label_amounts):\n",
    "    correct_label = test_names[idx]\n",
    "    precisions = [] #used for average precision\n",
    "    found = 0\n",
    "    k_val = 0\n",
    "    recall = -1\n",
    "  \n",
    "    while (found < label_amounts[correct_label]):\n",
    "        true_positives = 0\n",
    "        false_positives = 0\n",
    "        \n",
    "        \n",
    "        for i in range(0,k_val+1):\n",
    "            if (train_names[index[i]] == correct_label):\n",
    "                true_positives+=1\n",
    "                #Will be equal to precision at last correct in image in range\n",
    "                precision = true_positives/(true_positives + false_positives)\n",
    "                \n",
    "            else:\n",
    "                false_positives+=1\n",
    "                precision = -1\n",
    "            \n",
    "        \n",
    "        #If Relevant Document found in this iteration add its precision value \n",
    "        if (precision != -1):\n",
    "            precisions.append(precision)\n",
    "        \n",
    "        #Check if last value was correct, if so update found\n",
    "        if (train_names[index[i]] == correct_label):\n",
    "            found+=1\n",
    "            \n",
    "        k_val+=1\n",
    "    \n",
    "     #If empty add a zero to array for averaging\n",
    "    if not precisions:\n",
    "            precisions.append(0)\n",
    "    \n",
    "        \n",
    "    #Calculate Average Precision\n",
    "    average_precision = np.average(precisions)\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "#Sort the test data based on euclidean distance calculated from the training data\n",
    "def calculate_mean_average_precision(train_data, test_data, train_names, test_names):\n",
    "    images_displayed = 0\n",
    "    label_amounts = pd.value_counts(train_names)\n",
    "    \n",
    "    # MODIFIED LINE precision -> average_precisions = []\n",
    "    average_precisions = []\n",
    "    recalls = []\n",
    "    precisions_at_k = []\n",
    "    \n",
    "    \n",
    "    for idx, query in enumerate(test_data):\n",
    "        #Calculate first k closest iamges\n",
    "        query = query.reshape((1, -1))\n",
    "        D = euclidean_distances(train_data, query).squeeze()\n",
    "        index = np.argsort(D)\n",
    "    \n",
    "    \n",
    "        #Calcualte Metrics for Current Query\n",
    "        average_precision = calculate_average_precision(index, idx, train_names, test_names, label_amounts)\n",
    "            \n",
    "        #Append Results\n",
    "        average_precisions.append(average_precision)\n",
    "        \n",
    "    mAP = np.average(average_precisions)\n",
    "    return mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 55 Test images | 567 Train images\n",
      "\n",
      "Loaded in 55 Test names | 567 Train names\n",
      "\n",
      "Loaded in 55 Test pixels | 567 Train pixels\n",
      "\n",
      "Loaded in 55 Test 10-dim SIFT features | 567 Train 10-dim SIFT features\n",
      "Loaded in 55 Test 100-dim SIFT features | 567 Train 100-dim SIFT features\n",
      "Loaded in 55 Test 1000-dim SIFT features | 567 Train 1000-dim SIFT features\n",
      "Loaded in 55 Test 10000-dim SIFT features | 567 Train 10000-dim SIFT features\n",
      "Loaded in 55 Test 20000-dim SIFT features | 567 Train 20000-dim SIFT features\n",
      "Loaded in 55 Test 50000-dim SIFT features | 567 Train 50000-dim SIFT features\n",
      "Loaded in 55 Test 100000-dim SIFT features | 567 Train 100000-dim SIFT features\n",
      "\n",
      "Loading Complete!\n",
      "\n",
      "File names: test_images, train_images, test_names, train_names, test_pixels, train_pixels, SIFT_features\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# setting path name (make sure this notebook and the oxford_data folder are in the same directory/folder)\n",
    "os.chdir(\"/home/sean/Code/Pawsey/\")\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"oxford_data\")\n",
    "\n",
    "# Loading in Images:\n",
    "test_images = np.load(os.path.join(path, \"test_images.npy\"), allow_pickle=True)\n",
    "train_images = np.load(os.path.join(path, \"train_images.npy\"), allow_pickle=True)\n",
    "print(\"Loaded in {} Test images | {} Train images\\n\".format(len(test_images), len(train_images)))\n",
    "\n",
    "# Loading in Names:\n",
    "test_names = np.load(os.path.join(path, \"test_names.npy\"), allow_pickle=True)\n",
    "train_names= np.load(os.path.join(path, \"train_names.npy\"), allow_pickle=True)\n",
    "print(\"Loaded in {} Test names | {} Train names\\n\".format(len(test_names), len(train_names)))\n",
    "\n",
    "# Loading in Pixel features:pixels\n",
    "test_pixels = np.load(os.path.join(path, \"test_pixels.npy\"), allow_pickle=True)\n",
    "train_pixels= np.load(os.path.join(path, \"train_pixels.npy\"), allow_pickle=True)\n",
    "print(\"Loaded in {} Test pixels | {} Train pixels\\n\".format(len(test_pixels), len(train_pixels)))\n",
    "\n",
    "# Loading in SIFT features:\n",
    "SIFT_features = [[],[],[],[],[],[],[]]\n",
    "new_path = os.path.join(path, \"NPY files for BoVW\")\n",
    "for idx, i in enumerate([10, 100, 1000, 10000, 20000, 50000, 100000]):\n",
    "    path = os.path.join(new_path, \"bovw files for {} Words\".format(i))\n",
    "    test = np.load(os.path.join(path, \"BoW_Test.npy\"), allow_pickle=True)\n",
    "    train = np.load(os.path.join(path, \"BoW_Train.npy\"), allow_pickle=True)\n",
    "    SIFT_features[idx].append(test)\n",
    "    SIFT_features[idx].append(train)\n",
    "    print(\"Loaded in {} Test {}-dim SIFT features | {} Train {}-dim SIFT features\".format(len(test_images), i, len(train_images), i))\n",
    "    \n",
    "print(\"\\nLoading Complete!\\n\")\n",
    "print(\"File names: test_images, train_images, test_names, train_names, test_pixels, train_pixels, SIFT_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_average_precision(SIFT_features[0][1], SIFT_features[0][0], train_names, test_names, )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
